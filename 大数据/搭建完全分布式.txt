用5台机器搭建 完全分布式
 1个 master
 4个 slave

 master  192.168.80.151
 slave1  192.168.80.161
 slave2  192.168.80.162 
 slave3  192.168.80.163
 slave4  192.168.80.164


1.首先装Linux系统的虚拟机
  修改IP地址 
  vi /etc/sysconfig/network-scripts/ifcong-eth0
  修改dns
  vi /etc/resolv.conf         nameserver 119.29.29.29    或者8.8.8.8
  重启IP服务
  service network restart
  关闭防火墙
  service iptables stop
  chkconfig iptables off
  修改映射关系
  vi /etc/hosts
  修改主机名
  vi /etc/sysconfig/network
  
2.	(1)安装JDK  tar -zxvf 文件名    可以看见解压状态 
			 tar -xf  文件名  	  看不见解压状态	
	并配置环境变量 
			 vi /etc/profile.d/java.sh          注：一般配置文件都放在/etc下的profile.d中
			 JAVA_HOME=/soft/jdk
			 PATH=$PATH:$JAVA_HOME/bin
			 CLASSPATH=$CLASSPATH:$JAVA_HOME/lib
			 export JAVA_HOME PATH CLASSPATH
	执行java.sh文件   source /etc/profile.d/java.sh
	检查是否配置成功  java -version   如果出来版本信息证明配置成功
	
	(2)安装hadoop    本人用的版本 hadoop-2.7.3.tar.gz    从Apache官网下载即可
			tar -zxvf 文件名    可以看见解压状态 
			tar -xf  文件名  	  看不见解压状态
	并配置环境变量.......
			vi /etc/profile.d/hadoop.sh          注：一般配置文件都放在/etc下的profile.d中
			 HADOOP_HOME=/soft/hadoop
			 PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
			 export HADOOP_HOME PATH
	执行hadoop.sh文件   source /etc/profile.d/hadoop.sh
	检查是否配置成功  hadoop version   如果出来版本信息证明配置成功
	
3.  配置hadoop的相关配置文件 /soft/hadoop/etc/hadoop

		配置core-site.xml文件
		 <configuration>
			<property>
				<name>fs.defaultFS</name>
				<value>hdfs://master:9000</value>
			</property>
			<property>
				<name>hadoop.tmp.dir</name>
				<value>/hadoop/tmp</value>
			</property>
		</configuration>
		在相应地方创建文件夹/hadoop/tmp
		
		配置hdfs-site.xml文件
			<configuration>
				<property>
					<name>dfs.replication</name>  
					<value>3</value>  
				</property>
				<property>
					<name>dfs.namenode.name.dir</name>
					<value>/hadoop/tmp/dfs/name</value>
				</property>
				<property>
					<name>dfs.datanode.data.dir</name>
					<value>/hadoop/tmp/dfs/data</value>
				</property>
				<property>
					<name>dfs.permissions.enabled</name>
					<value>false</value>
				</property>
			</configuration>
		在相应地方创建文件夹/hadoop/tmp/dfs/data和/hadoop/tmp/dfs/name
		
		配置mapred-site.xml		
		将mapred-site.xml.template 复制一份 改名为 mapred-site.xml
			<configuration>
				<property>  
					<name>mapreduce.framework.name</name>  
					<value>yarn</value>  
				</property>  
			</configuration>
			
		配置yarn-site.xml文件
			<configuration>
				 <property>  
					<name>yarn.resourcemanager.hostname</name>  
					<value>hadoop</value>  
				</property>  
				<property>  
					<name>yarn.nodemanager.aux-services</name>  
					<value>mapreduce_shuffle</value>  
				</property>  
			</configuration>
			
			
4.安装ssh   yum -y install openssh-clients openssh-server
		
		生成公钥和私钥
		ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa   （注意 p是大写）
		进入目录  # cd ~/.ssh
		将公钥 导入到秘钥库  其实就是个复制文件  
		# cp id_rsa.pub  authorized_keys
		测试
		# ssh localhost  如果不用再输入密码了 则成功

		
5. 克隆slave   
	修改IP		vi /etc/sysconfig/network-scripts/ifcfg-eth0    并删除UUID和HWADDR	
	修改主机名	vi /etc/sysconfig/network
	删除/etc/udev/rules.d/70-persistent-net.rules
	修改maseter 的配置文件   /soft/hadoop/etc/hadoop/slaves  将4个datanode放进来(slave1,slave2,slave3,slave4)

		
6. 启动hadoop   
		(1)  nameNode格式化
			hadoop namenode -format
		(2) 启动hadoop进程 
			start-all.sh
		(3) 查看进程   
			jps
		有以下五个进城费说明搭建成功		
			1412 NameNode  
			1910 NodeManager  
			1499 DataNode  
			1676 SecondaryNameNode  
			1821 ResourceManager 
			
			
			
			
			
7.  如果ssh连接出现The authenticity of host can't be established的问题
	修改/etc/ssh/ssh_config文件的配置，以后则不会再出现此问题
	在最后面添加：
		StrictHostKeyChecking no
		UserKnownHostsFile /dev/null
		
		
		
8  如果DataNode没有启动  hadoop-daemon.sh start datanode